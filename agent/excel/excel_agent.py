import asyncio
import json
import logging
import os
import time
import traceback
import uuid
from typing import Optional, Dict, Any, Union

from langgraph.graph.state import CompiledStateGraph

from agent.excel.excel_agent_state import ExcelAgentState
from agent.excel.excel_graph import create_excel_graph
from constants.code_enum import DataTypeEnum
from services.user_service import decode_jwt_token, add_user_record, query_user_qa_record
from agent.excel.excel_duckdb_manager import close_duckdb_manager, get_chat_duckdb_manager

from langfuse import get_client
from langfuse.langchain import CallbackHandler

logger = logging.getLogger(__name__)

# æ­¥éª¤åç§°æ˜ å°„ï¼ˆä¸­æ–‡ï¼‰
STEP_NAME_MAP = {
    "excel_parsing": "æ–‡ä»¶è§£æ...",
    "early_recommender": "æ¨èé—®é¢˜ç”Ÿæˆ...",
    "sql_generator": "SQLç”Ÿæˆ...",
    "sql_executor": "SQLæ‰§è¡Œ...",
    "chart_generator": "å›¾è¡¨é…ç½®...",
    "summarize": "ç»“æœæ€»ç»“...",
    "parallel_collector": "å¹¶è¡Œå¤„ç†ï¼ˆå›¾è¡¨é…ç½®ä¸ç»“æœæ€»ç»“ï¼‰...",
    "unified_collector": "ç»Ÿä¸€æ”¶é›†ï¼ˆç»“æœæ€»ç»“â†’å›¾è¡¨æ•°æ®â†’æ¨èé—®é¢˜ï¼‰...",
    "data_render": "æ•°æ®æ¸²æŸ“...",
    "data_render_apache": "æ•°æ®æ¸²æŸ“...",
    "question_recommender": "æ¨èé—®é¢˜...",
}


class ExcelAgent:
    """
    è¡¨æ ¼é—®ç­”æ™ºèƒ½ä½“
    """

    def __init__(self):
        # å­˜å‚¨è¿è¡Œä¸­çš„ä»»åŠ¡
        self.running_tasks = {}
        self.excel_graph = create_excel_graph()
        # æ˜¯å¦å¯ç”¨é“¾è·¯è¿½è¸ª
        self.ENABLE_TRACING = os.getenv("LANGFUSE_TRACING_ENABLED", "true").lower() == "true"
        # å­˜å‚¨æ­¥éª¤å¼€å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—è€—æ—¶ï¼‰
        self.step_start_times = {}
        # å­˜å‚¨æ­¥éª¤çš„ progressId
        self.step_progress_ids = {}

    async def run_excel_agent(
        self,
        query: str,
        response=None,
        chat_id: str = None,
        uuid_str: str = None,
        user_token=None,
        file_list: list = None,
    ) -> None:
        """
        è¿è¡Œè¡¨æ ¼æ™ºèƒ½ä½“
        :param query:
        :param response:
        :param chat_id:
        :param uuid_str:
        :param user_token:
        :param file_list
        :return:
        """
        t02_answer_data = []  # ç”¨äºä¿å­˜ summarize å†…å®¹
        t04_answer_data = {}  # ç”¨äºä¿å­˜å›¾è¡¨æ•°æ®
        summarize_content = ""  # ç”¨äºå•ç‹¬ä¿å­˜ summarize ä¿¡æ¯ï¼ˆmarkdownæ ¼å¼ï¼‰
        sql_statement = ""  # ç”¨äºä¿å­˜ SQL è¯­å¥
        current_step = None

        # å®ç°ä¸Šä¼ ä¸€æ¬¡å¤šæ¬¡å¯¹è¯çš„æ•ˆæœ é»˜è®¤å•è½®å¯¹è¯å–æœ€æ–°ä¸Šä¼ çš„æ–‡ä»¶
        if file_list is None or len(file_list) == 0:
            user_qa_record = query_user_qa_record(chat_id)[0]
            if user_qa_record:
                file_list = json.loads(user_qa_record["file_key"])
        try:
            initial_state = ExcelAgentState(
                user_query=query,
                file_list=file_list,
                chat_id=chat_id,  # chat_id
                file_metadata={},  # æ–‡ä»¶å…ƒæ•°æ®
                sheet_metadata={},  # Sheetå…ƒæ•°æ®
                db_info=[],  # æ”¯æŒå¤šä¸ªè¡¨ç»“æ„
                catalog_info={},  # Catalogä¿¡æ¯
                generated_sql="",
                chart_type="",
                chart_config=None,  # å›¾è¡¨é…ç½®ï¼ˆå’Œæ•°æ®é—®ç­”ä¸€è‡´ï¼‰
                execution_result=None,  # ä¿®æ”¹ï¼šä½¿ç”¨ExecutionResultå¯¹è±¡
                report_summary="",
                render_data=None,  # æ¸²æŸ“æ•°æ®ï¼ˆå’Œæ•°æ®é—®ç­”ä¸€è‡´ï¼‰
            )
            graph: CompiledStateGraph = self.excel_graph

            # è·å–ç”¨æˆ·ä¿¡æ¯ æ ‡è¯†å¯¹è¯çŠ¶æ€
            user_dict = await decode_jwt_token(user_token)
            task_id = user_dict["id"]
            task_context = {"cancelled": False}
            self.running_tasks[task_id] = task_context

            # å‡†å¤‡ tracing é…ç½®
            config = {}
            if self.ENABLE_TRACING:
                langfuse_handler = CallbackHandler()
                callbacks = [langfuse_handler]
                config = {
                    "callbacks": callbacks,
                    "metadata": {
                        "langfuse_session_id": chat_id,
                    },
                }

            # å¼‚æ­¥æµå¼æ‰§è¡Œå‚æ•°
            stream_kwargs = {
                "input": initial_state,
                "stream_mode": "updates",
                "config": config,
            }

            # å¦‚æœå¯ç”¨ tracingï¼ŒåŒ…è£¹åœ¨ trace ä¸Šä¸‹æ–‡ä¸­
            if self.ENABLE_TRACING:
                langfuse = get_client()
                with langfuse.start_as_current_observation(
                    input=query,
                    as_type="agent",
                    name="è¡¨æ ¼é—®ç­”",
                ) as rootspan:
                    user_info = await decode_jwt_token(user_token)
                    user_id = user_info.get("id")
                    rootspan.update_trace(session_id=chat_id, user_id=user_id)

                    async for chunk_dict in graph.astream(**stream_kwargs):
                        current_step, t02_answer_data, summarize_content, sql_statement = await self._process_chunk(
                            chunk_dict, response, task_id, current_step, t02_answer_data, t04_answer_data, summarize_content, sql_statement
                        )
                        # è·Ÿè¸ª sql_generator èŠ‚ç‚¹åçš„ SQL è¯­å¥
                        if "sql_generator" in chunk_dict:
                            step_value = chunk_dict.get("sql_generator", {})
                            generated_sql = step_value.get("generated_sql", "")
                            if generated_sql and generated_sql != "No SQL query generated":
                                sql_statement = generated_sql
            else:
                async for chunk_dict in graph.astream(**stream_kwargs):
                    current_step, t02_answer_data, summarize_content, sql_statement = await self._process_chunk(
                        chunk_dict, response, task_id, current_step, t02_answer_data, t04_answer_data, summarize_content, sql_statement
                    )
                    # è·Ÿè¸ª sql_generator èŠ‚ç‚¹åçš„ SQL è¯­å¥
                    if "sql_generator" in chunk_dict:
                        step_value = chunk_dict.get("sql_generator", {})
                        generated_sql = step_value.get("generated_sql", "")
                        if generated_sql and generated_sql != "No SQL query generated":
                            sql_statement = generated_sql

            # åªæœ‰åœ¨æœªå–æ¶ˆçš„æƒ…å†µä¸‹æ‰ä¿å­˜è®°å½•
            if not self.running_tasks[task_id]["cancelled"]:
                # t02_answer ä¿å­˜ summarize ä¿¡æ¯ï¼ˆmarkdownæ ¼å¼ï¼‰
                # å¦‚æœæ²¡æœ‰ summarizeï¼Œåˆ™ä¿å­˜ç©ºå­—ç¬¦ä¸²
                final_t02_answer = [summarize_content] if summarize_content else []
                
                record_id = await add_user_record(
                    uuid_str,
                    chat_id,
                    query,
                    final_t02_answer,  # åªä¿å­˜ summarize ä¿¡æ¯
                    t04_answer_data,  # ä¿å­˜å›¾è¡¨æ•°æ®
                    "FILEDATA_QA",
                    user_token,
                    file_list,
                    sql_statement=sql_statement,  # ä¿å­˜ SQL è¯­å¥
                )
                # å‘é€record_idåˆ°å‰ç«¯ï¼Œç”¨äºå®æ—¶å¯¹è¯æ—¶æ˜¾ç¤ºSQLå›¾æ ‡
                if record_id and response:
                    await self._send_response(
                        response=response,
                        content={"record_id": record_id},
                        data_type=DataTypeEnum.RECORD_ID.value[0]
                    )

        except asyncio.CancelledError:
            await response.write(self._create_response("\n> è¿™æ¡æ¶ˆæ¯å·²åœæ­¢", "info", DataTypeEnum.ANSWER.value[0]))
            await response.write(self._create_response("", "end", DataTypeEnum.STREAM_END.value[0]))
        except Exception as e:
            traceback.print_exception(e)
            logger.error(f"è¡¨æ ¼é—®ç­”æ™ºèƒ½ä½“è¿è¡Œå¼‚å¸¸: {e}")
            error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            await self._send_response(response, error_msg, "error")

    async def _process_chunk(
        self,
        chunk_dict,
        response,
        task_id,
        current_step,
        t02_answer_data,
        t04_answer_data,
        summarize_content,
        sql_statement,
    ):
        """
        å¤„ç†å•ä¸ªæµå¼å—æ•°æ®
        """
        # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
        if task_id in self.running_tasks and self.running_tasks[task_id]["cancelled"]:
            await response.write(self._create_response("\n> è¿™æ¡æ¶ˆæ¯å·²åœæ­¢", "info", DataTypeEnum.ANSWER.value[0]))
            # å‘é€æœ€ç»ˆåœæ­¢ç¡®è®¤æ¶ˆæ¯
            await response.write(self._create_response("", "end", DataTypeEnum.STREAM_END.value[0]))
            raise asyncio.CancelledError()

        langgraph_step, step_value = next(iter(chunk_dict.items()))

        # å¤„ç†æ­¥éª¤å˜æ›´ï¼ˆå‘é€å‰ä¸€ä¸ªæ­¥éª¤çš„å®Œæˆä¿¡æ¯å’Œæ–°æ­¥éª¤çš„å¼€å§‹ä¿¡æ¯ï¼‰
        current_step, t02_answer_data = await self._handle_step_change(
            response, current_step, langgraph_step, t02_answer_data
        )

        # å¤„ç†å…·ä½“æ­¥éª¤å†…å®¹
        if step_value:
            summarize_content, sql_statement = await self._process_step_content(
                response, langgraph_step, step_value, t02_answer_data, t04_answer_data, summarize_content, sql_statement
            )
            
            # æ­¥éª¤å†…å®¹å¤„ç†å®Œæˆåï¼Œå‘é€å®Œæˆä¿¡æ¯ï¼ˆå¦‚æœæ˜¯æœ€åä¸€ä¸ªæ­¥éª¤ï¼Œç¡®ä¿å‘é€å®Œæˆä¿¡æ¯ï¼‰
            if langgraph_step in self.step_progress_ids:
                progress_id = self.step_progress_ids.get(langgraph_step)
                if progress_id:
                    step_name_cn = STEP_NAME_MAP.get(langgraph_step, langgraph_step)
                    await self._send_step_progress(
                        response=response,
                        step=langgraph_step,
                        step_name=step_name_cn,
                        status="complete",
                        progress_id=progress_id,
                    )
                    # æ¸…ç†å·²å®Œæˆçš„æ­¥éª¤ progressId
                    del self.step_progress_ids[langgraph_step]

        return current_step, t02_answer_data, summarize_content, sql_statement

    async def _handle_step_change(
        self,
        response,
        current_step: Optional[str],
        new_step: str,
        t02_answer_data: list,
    ) -> tuple:
        """
        å¤„ç†æ­¥éª¤å˜æ›´
        """
        # è®°å½•æ–°æ­¥éª¤å¼€å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—è€—æ—¶ï¼‰
        if new_step and new_step not in self.step_start_times:
            self.step_start_times[new_step] = time.perf_counter()
            logger.debug(f"æ­¥éª¤ {new_step} å¼€å§‹")
            
            # ç”Ÿæˆæ–°çš„ progressId å¹¶å‘é€æ­¥éª¤å¼€å§‹ä¿¡æ¯
            progress_id = str(uuid.uuid4())
            self.step_progress_ids[new_step] = progress_id
            step_name_cn = STEP_NAME_MAP.get(new_step, new_step)
            await self._send_step_progress(
                response=response,
                step=new_step,
                step_name=step_name_cn,
                status="start",
                progress_id=progress_id,
            )

        return new_step, t02_answer_data

    async def _process_step_content(
        self,
        response,
        step_name: str,
        step_value: Dict[str, Any],
        t02_answer_data: list,
        t04_answer_data: Dict[str, Any],
        summarize_content: str,
        sql_statement: str,
    ) -> tuple:
        """
        å¤„ç†å„ä¸ªæ­¥éª¤çš„å†…å®¹
        """
        # è®¡ç®—æ­¥éª¤è€—æ—¶ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
        elapsed_time = None
        if step_name in self.step_start_times:
            start_time = self.step_start_times[step_name]
            end_time = time.perf_counter()
            elapsed_time = end_time - start_time
            logger.debug(f"æ­¥éª¤ {step_name} è€—æ—¶: {elapsed_time:.3f}ç§’")
            del self.step_start_times[step_name]
        
        content_map = {
            "excel_parsing": lambda: self._format_multi_file_table_info(step_value),
            "sql_generator": lambda: self._format_sql_generator_output(step_value),
            "sql_executor": lambda: self._format_execution_result(step_value.get("execution_result")),
            "chart_generator": lambda: self._format_chart_generator_output(step_value),
            "summarize": lambda: step_value.get("report_summary", ""),
            "data_render": lambda: step_value.get("render_data", {}) if step_value.get("render_data") else {},
            "data_render_apache": lambda: step_value.get("render_data", {}) if step_value.get("render_data") else {},
        }

        if step_name in content_map:
            content = content_map[step_name]()
            
            # ç‰¹æ®Šå¤„ç†ï¼šæ”¶é›† SQL è¯­å¥
            if step_name == "sql_generator":
                sql_from_state = step_value.get("generated_sql", "")
                if sql_from_state and sql_from_state != "No SQL query generated":
                    sql_statement = sql_from_state
            
            # ç‰¹æ®Šå¤„ç†ï¼šæ”¶é›† summarize ä¿¡æ¯ï¼ˆmarkdownæ ¼å¼ï¼‰
            if step_name == "summarize":
                summarize_from_state = step_value.get("report_summary", "")
                if summarize_from_state:
                    # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²æ ¼å¼ï¼ˆmarkdownæ ¼å¼ï¼‰
                    if isinstance(summarize_from_state, dict):
                        if "content" in summarize_from_state:
                            summarize_content = str(summarize_from_state["content"])
                        elif "summary" in summarize_from_state:
                            summarize_content = str(summarize_from_state["summary"])
                        else:
                            md_lines = []
                            for key, value in summarize_from_state.items():
                                md_lines.append(f"**{key}**: {value}")
                            summarize_content = "\n\n".join(md_lines)
                    else:
                        summarize_content = str(summarize_from_state)
            
            # æ•°æ®æ¸²æŸ“èŠ‚ç‚¹è¿”å›ä¸šåŠ¡æ•°æ®
            data_type = (
                DataTypeEnum.BUS_DATA.value[0] if step_name in ["data_render", "data_render_apache"] else DataTypeEnum.ANSWER.value[0]
            )

            # åªè¾“å‡º summarize æ­¥éª¤åˆ°å‰ç«¯ï¼Œå…¶ä»–æ­¥éª¤ä¿¡æ¯ä¸è¾“å‡º
            # ä½†ä¿ç•™ data_render å’Œ data_render_apache çš„ä¸šåŠ¡æ•°æ®è¾“å‡º
            should_send = step_name in ["summarize", "data_render", "data_render_apache"]

            if should_send:
                # data_render å’Œ data_render_apache æ­¥éª¤çš„å†…å®¹æ˜¯å­—å…¸ï¼Œç›´æ¥ä½œä¸ºä¸šåŠ¡æ•°æ®å‘é€
                if step_name in ["data_render", "data_render_apache"]:
                    await self._send_response(response=response, content=content, data_type=data_type)
                elif step_name == "summarize":
                    # summarize æ­¥éª¤ï¼šç›´æ¥è¾“å‡ºå†…å®¹ï¼Œä¸åŒ…å«æ ‡é¢˜å’Œè€—æ—¶ä¿¡æ¯
                    # ç¡®ä¿ content æ˜¯å­—ç¬¦ä¸²ç±»å‹
                    if isinstance(content, dict):
                        content = json.dumps(content, ensure_ascii=False, indent=2)
                    await self._send_response(response=response, content=content, data_type=data_type)
                else:
                    # å…¶ä»–æ­¥éª¤éœ€è¦æ ¼å¼åŒ–è¾“å‡ºï¼ˆè™½ç„¶ç°åœ¨ä¸ä¼šæ‰§è¡Œåˆ°è¿™é‡Œï¼Œä½†ä¿ç•™ä»¥é˜²ä¸‡ä¸€ï¼‰
                    step_display_name = STEP_NAME_MAP.get(step_name, step_name)
                    # ç¡®ä¿ content æ˜¯å­—ç¬¦ä¸²ç±»å‹
                    if isinstance(content, dict):
                        content = json.dumps(content, ensure_ascii=False, indent=2)
                    formatted_content = self._format_step_output(step_display_name, content, step_name, None)
                    await self._send_response(response=response, content=formatted_content, data_type=data_type)

                # åªæ”¶é›† summarize æ­¥éª¤çš„å†…å®¹åˆ° t02_answer_data
                if step_name == "summarize" and data_type == DataTypeEnum.ANSWER.value[0]:
                    t02_answer_data.append(content)

            # è¿™é‡Œè®¾ç½®æ¸²æŸ“æ•°æ®ï¼ˆå’Œæ•°æ®é—®ç­”ä¸€è‡´ï¼‰
            if step_name in ["data_render", "data_render_apache"] and data_type == DataTypeEnum.BUS_DATA.value[0]:
                render_data = step_value.get("render_data")
                if render_data is not None and render_data:
                    t04_answer_data.clear()
                    t04_answer_data.update({"data": render_data, "dataType": data_type})
                else:
                    t04_answer_data.clear()

            # å¯¹äºéæ¸²æŸ“æ­¥éª¤ï¼Œåˆ·æ–°å“åº”
            if step_name not in ["data_render", "data_render_apache"]:
                if hasattr(response, "flush"):
                    await response.flush()
                await asyncio.sleep(0)
        
        # å¤„ç†ç»Ÿä¸€æ”¶é›†èŠ‚ç‚¹ï¼šæŒ‰é¡ºåºæ¨é€ summarize â†’ å›¾è¡¨æ•°æ® â†’ æ¨èé—®é¢˜
        # æ³¨æ„ï¼šunified_collector èŠ‚ç‚¹ä¸åœ¨ content_map ä¸­å¤„ç†ï¼Œé¿å…å‘é€æ ¼å¼åŒ–æ¶ˆæ¯åˆ°å‰ç«¯
        if step_name == "unified_collector":
            updated_summarize_content = await self._process_unified_collector(
                response, step_value, t02_answer_data, t04_answer_data, summarize_content
            )
            # å¤„ç†å®Œ unified_collector åç›´æ¥è¿”å›ï¼Œä¸å†é€šè¿‡ content_map å‘é€å†…å®¹
            return updated_summarize_content or summarize_content, sql_statement
        
        # å¤„ç†æ¨èé—®é¢˜ï¼šå°†æ¨èé—®é¢˜åˆå¹¶åˆ°å·²æœ‰çš„å›¾è¡¨æ•°æ®ä¸­å‘é€åˆ°å‰ç«¯ï¼ˆåœ¨ content_map ä¹‹å¤–å¤„ç†ï¼‰
        # æ³¨æ„ï¼šå¦‚æœä½¿ç”¨äº† unified_collectorï¼Œè¿™ä¸ªåˆ†æ”¯å¯èƒ½ä¸ä¼šæ‰§è¡Œ
        if step_name == "question_recommender":
            recommended_questions = step_value.get("recommended_questions", [])
            logger.info(
                f"question_recommender æ­¥éª¤: è·å–åˆ°æ¨èé—®é¢˜æ•°é‡: "
                f"{len(recommended_questions) if recommended_questions else 0}, "
                f"t04_answer_data: {t04_answer_data}"
            )

            if recommended_questions and isinstance(recommended_questions, list) and len(recommended_questions) > 0:
                # è·å–å·²æœ‰çš„å›¾è¡¨æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºæ–°çš„æ•°æ®ç»“æ„
                if (
                    t04_answer_data
                    and "data" in t04_answer_data
                    and isinstance(t04_answer_data["data"], dict)
                    and t04_answer_data["data"]
                ):
                    # å°†æ¨èé—®é¢˜æ·»åŠ åˆ°å·²æœ‰çš„å›¾è¡¨æ•°æ®ä¸­
                    t04_answer_data["data"]["recommended_questions"] = recommended_questions
                    payload = t04_answer_data["data"]
                    data_type = t04_answer_data.get("dataType", DataTypeEnum.BUS_DATA.value[0])
                else:
                    # å¦‚æœæ²¡æœ‰å›¾è¡¨æ•°æ®ï¼Œä»…ä½¿ç”¨æ¨èé—®é¢˜æ„å»ºæ•°æ®ç»“æ„
                    logger.warning(
                        f"question_recommender æ­¥éª¤: t04_answer_data ä¸ºç©ºæˆ–æ— æ•ˆï¼Œ"
                        f"t04_answer_data: {t04_answer_data}"
                    )
                    payload = {"recommended_questions": recommended_questions}
                    data_type = DataTypeEnum.BUS_DATA.value[0]
                    # åŒæ­¥æ›´æ–° t04_answer_dataï¼Œç¡®ä¿ä¼šè¢«ä¿å­˜åˆ°æ•°æ®åº“
                    t04_answer_data.clear()
                    t04_answer_data.update({"data": payload, "dataType": data_type})

                # æ¨é€æ¨èé—®é¢˜æ•°æ®åˆ°å‰ç«¯
                await self._send_response(
                    response=response,
                    content=payload,
                    data_type=data_type,
                )
                logger.info(
                    f"å·²å‘é€ {len(recommended_questions)} ä¸ªæ¨èé—®é¢˜åˆ°å‰ç«¯ï¼Œ"
                    f"å®Œæ•´æ•°æ®: {t04_answer_data}"
                )
            else:
                logger.warning(
                    f"question_recommender æ­¥éª¤: æ¨èé—®é¢˜ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯ï¼Œ"
                    f"recommended_questions: {recommended_questions}"
                )
        
        return summarize_content, sql_statement

    async def _process_unified_collector(
        self,
        response,
        step_value: Dict[str, Any],
        t02_answer_data: list,
        t04_answer_data: Dict[str, Any],
        summarize_content: str,
    ) -> str:
        """
        å¤„ç†ç»Ÿä¸€æ”¶é›†èŠ‚ç‚¹ï¼šæŒ‰é¡ºåºæ¨é€ summarize â†’ å›¾è¡¨æ•°æ® â†’ æ¨èé—®é¢˜
        
        è¦æ±‚ï¼š
        1. é¦–å…ˆæ¨é€ summarizeï¼ˆæ–‡æœ¬æ€»ç»“ï¼‰
        2. ç„¶åæ¨é€å›¾è¡¨æ•°æ®ï¼ˆrender_dataï¼‰
        3. æœ€åæ¨é€æ¨èé—®é¢˜ï¼ˆrecommended_questionsï¼‰
        
        Returns:
            æ›´æ–°åçš„ summarize_content
        """
        logger.info("ğŸ“¦ å¼€å§‹å¤„ç†ç»Ÿä¸€æ”¶é›†èŠ‚ç‚¹")
        logger.info(f"ğŸ“‹ step_value keys: {list(step_value.keys())}")
        logger.info(f"ğŸ“‹ step_value recommended_questions: {step_value.get('recommended_questions')}")
        
        # 1. æ¨é€ summarizeï¼ˆç»“æœæ€»ç»“ï¼‰
        report_summary = step_value.get("report_summary")
        if report_summary:
            logger.info("ğŸ“¤ æ¨é€ summarizeï¼ˆç»“æœæ€»ç»“ï¼‰")
            # ç¡®ä¿ report_summary æ˜¯å­—ç¬¦ä¸²æ ¼å¼
            if isinstance(report_summary, dict):
                if "content" in report_summary:
                    report_summary = str(report_summary["content"])
                elif "summary" in report_summary:
                    report_summary = str(report_summary["summary"])
                else:
                    report_summary = json.dumps(report_summary, ensure_ascii=False, indent=2)
            else:
                report_summary = str(report_summary)
            
            await self._send_response(
                response=response,
                content=report_summary,
                data_type=DataTypeEnum.ANSWER.value[0],
            )
            # æ”¶é›†åˆ° t02_answer_data
            t02_answer_data.append(report_summary)
            # æ›´æ–° summarize_content
            summarize_content = report_summary
        
        # 2. æ¨é€å›¾è¡¨æ•°æ®ï¼ˆrender_dataï¼‰
        render_data = step_value.get("render_data", {})
        if render_data:
            logger.info("ğŸ“¤ æ¨é€å›¾è¡¨æ•°æ®")
            # æ›´æ–° t04_answer_data
            t04_answer_data.clear()
            t04_answer_data.update({"data": render_data, "dataType": DataTypeEnum.BUS_DATA.value[0]})
            
            # å‘é€å›¾è¡¨æ•°æ®
            await self._send_response(
                response=response,
                content=render_data,
                data_type=DataTypeEnum.BUS_DATA.value[0],
            )
        
        # 3. æ¨é€æ¨èé—®é¢˜ï¼ˆrecommended_questionsï¼‰
        recommended_questions = step_value.get("recommended_questions", [])
        logger.info(f"ğŸ“‹ æ£€æŸ¥æ¨èé—®é¢˜: {recommended_questions}, ç±»å‹: {type(recommended_questions)}, é•¿åº¦: {len(recommended_questions) if isinstance(recommended_questions, list) else 'N/A'}")
        
        if recommended_questions and isinstance(recommended_questions, list) and len(recommended_questions) > 0:
            logger.info(f"ğŸ“¤ æ¨é€æ¨èé—®é¢˜ï¼Œæ•°é‡: {len(recommended_questions)}")
            
            # å°†æ¨èé—®é¢˜æ·»åŠ åˆ°å·²æœ‰çš„å›¾è¡¨æ•°æ®ä¸­
            if t04_answer_data and "data" in t04_answer_data and isinstance(t04_answer_data["data"], dict):
                t04_answer_data["data"]["recommended_questions"] = recommended_questions
                payload = t04_answer_data["data"]
                data_type = t04_answer_data.get("dataType", DataTypeEnum.BUS_DATA.value[0])
                logger.info(f"ğŸ“Š å°†æ¨èé—®é¢˜åˆå¹¶åˆ°å·²æœ‰å›¾è¡¨æ•°æ®ä¸­ï¼Œpayload keys: {list(payload.keys())}")
            else:
                # å¦‚æœæ²¡æœ‰å›¾è¡¨æ•°æ®ï¼Œä»…ä½¿ç”¨æ¨èé—®é¢˜æ„å»ºæ•°æ®ç»“æ„
                logger.info("ğŸ“Š æ²¡æœ‰å›¾è¡¨æ•°æ®ï¼Œä»…ä½¿ç”¨æ¨èé—®é¢˜æ„å»ºæ•°æ®ç»“æ„")
                payload = {"recommended_questions": recommended_questions}
                data_type = DataTypeEnum.BUS_DATA.value[0]
                t04_answer_data.clear()
                t04_answer_data.update({"data": payload, "dataType": data_type})
            
            # å‘é€æ¨èé—®é¢˜
            logger.info(f"ğŸ“¤ å‡†å¤‡å‘é€æ¨èé—®é¢˜åˆ°å‰ç«¯ï¼Œpayload: {payload}")
            await self._send_response(
                response=response,
                content=payload,
                data_type=data_type,
            )
            logger.info(f"âœ… å·²å‘é€ {len(recommended_questions)} ä¸ªæ¨èé—®é¢˜åˆ°å‰ç«¯")
        else:
            logger.warning(f"âš ï¸ æ¨èé—®é¢˜ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯: recommended_questions={recommended_questions}, type={type(recommended_questions)}")
        
        logger.info("âœ… ç»Ÿä¸€æ”¶é›†èŠ‚ç‚¹å¤„ç†å®Œæˆ")
        return summarize_content

    def _format_step_output(self, step_display_name: str, content: str, step_name: str, elapsed_time: Optional[float] = None) -> str:
        """
        æ ¼å¼åŒ–æ­¥éª¤è¾“å‡ºä¸º markdown æ ¼å¼ï¼ŒåŒ…å«æ­¥éª¤åç§°å’Œåˆ†éš”
        :param step_display_name: æ­¥éª¤æ˜¾ç¤ºåç§°ï¼ˆä¸­æ–‡ï¼‰
        :param content: æ­¥éª¤å†…å®¹ï¼ˆå­—ç¬¦ä¸²ï¼‰
        :param step_name: æ­¥éª¤åç§°ï¼ˆè‹±æ–‡ï¼‰
        :param elapsed_time: è€—æ—¶ï¼ˆç§’ï¼Œå·²åºŸå¼ƒï¼Œä¸å†ä½¿ç”¨ï¼‰
        :return: æ ¼å¼åŒ–åçš„ markdown å­—ç¬¦ä¸²
        """
        # ç¡®ä¿ content æ˜¯å­—ç¬¦ä¸²ç±»å‹
        if not isinstance(content, str):
            if isinstance(content, dict):
                content = json.dumps(content, ensure_ascii=False, indent=2)
            else:
                content = str(content)
        
        # æ„å»ºæ­¥éª¤æ ‡é¢˜ï¼ˆä¸åŒ…å«è€—æ—¶ä¿¡æ¯ï¼‰
        step_header = f"## ğŸ“‹ {step_display_name}\n\n"
        
        # æ ¹æ®æ­¥éª¤ç±»å‹å†³å®šæ˜¯å¦åŒ…è£…ä¸ºä»£ç å—
        if step_name == "summarize":
            # summarize æ­¥éª¤ï¼šå†…å®¹å·²ç»æ˜¯ markdown æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨ï¼Œä¸åŒ…è£…æˆä»£ç å—
            formatted = step_header + content
        elif content.strip().startswith("```"):
            # å†…å®¹å·²ç»æ˜¯ä»£ç å—æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
            formatted = step_header + content
        else:
            # å…¶ä»–æ­¥éª¤ï¼šæ ¹æ®æ­¥éª¤ç±»å‹é€‰æ‹©ä»£ç å—è¯­è¨€
            code_lang = "json" if step_name in ["sql_generator", "chart_generator", "question_recommender"] else "markdown"
            formatted = step_header + f"```{code_lang}\n{content}\n```"
        
        # æ·»åŠ åˆ†éš”çº¿ï¼Œç¡®ä¿æ¯ä¸ªæ­¥éª¤ç‹¬ç«‹åˆ†å¼€æ˜¾ç¤º
        separator = "\n\n---\n\n"
        
        return formatted + separator

    @staticmethod
    async def _send_step_progress(
        response,
        step: str,
        step_name: str,
        status: str,
        progress_id: str,
    ) -> None:
        """
        å‘é€æ­¥éª¤è¿›åº¦ä¿¡æ¯
        :param response: å“åº”å¯¹è±¡
        :param step: æ­¥éª¤æ ‡è¯†ï¼ˆè‹±æ–‡ï¼‰
        :param step_name: æ­¥éª¤åç§°ï¼ˆä¸­æ–‡ï¼‰
        :param status: çŠ¶æ€ï¼ˆ"start" æˆ– "complete"ï¼‰
        :param progress_id: è¿›åº¦IDï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰
        """
        if response:
            progress_data = {
                "type": "step_progress",
                "step": step,
                "stepName": step_name,
                "status": status,
                "progressId": progress_id,
            }
            formatted_message = {
                "data": progress_data,
                "dataType": DataTypeEnum.STEP_PROGRESS.value[0],
            }
            await response.write("data:" + json.dumps(formatted_message, ensure_ascii=False) + "\n\n")

    @staticmethod
    async def _send_response(
        response, content: Union[str, Dict[str, Any]], message_type: str = "continue", data_type: str = DataTypeEnum.ANSWER.value[0]
    ) -> None:
        """
        å‘é€å“åº”æ•°æ®
        :param response: å“åº”å¯¹è±¡
        :param content: å“åº”å†…å®¹ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸
        :param message_type: æ¶ˆæ¯ç±»å‹
        :param data_type: æ•°æ®ç±»å‹
        """
        if response:
            if data_type == DataTypeEnum.ANSWER.value[0]:
                formatted_message = {
                    "data": {
                        "messageType": message_type,
                        "content": content,
                    },
                    "dataType": data_type,
                }
            else:
                # ä¸šåŠ¡æ•°æ®ï¼ˆè¡¨æ ¼/å›¾è¡¨ï¼‰ï¼Œcontent æ˜¯å­—å…¸
                formatted_message = {"data": content, "dataType": data_type}

            await response.write("data:" + json.dumps(formatted_message, ensure_ascii=False) + "\n\n")

    @staticmethod
    def _create_response(
        content: str, message_type: str = "continue", data_type: str = DataTypeEnum.ANSWER.value[0]
    ) -> str:
        """
        å°è£…å“åº”ç»“æ„ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        """
        res = {
            "data": {"messageType": message_type, "content": content},
            "dataType": data_type,
        }
        return "data:" + json.dumps(res, ensure_ascii=False) + "\n\n"

    async def cancel_task(self, task_id: str) -> bool:
        """
        å–æ¶ˆæŒ‡å®šçš„ä»»åŠ¡
        :param task_id: ä»»åŠ¡ID
        :return: æ˜¯å¦æˆåŠŸå–æ¶ˆ
        """
        if task_id in self.running_tasks:
            self.running_tasks[task_id]["cancelled"] = True
            return True
        return False

    def cleanup_chat_session(self, chat_id: str) -> bool:
        """
        æ¸…ç†æŒ‡å®šchat_idçš„DuckDBä¼šè¯
        :param chat_id: èŠå¤©ID
        :return: æ˜¯å¦æˆåŠŸæ¸…ç†
        """
        try:
            return close_duckdb_manager(chat_id=chat_id)
        except Exception as e:
            logger.error(f"æ¸…ç†chat_id '{chat_id}' çš„DuckDBä¼šè¯å¤±è´¥: {str(e)}")
            return False

    def get_chat_session_stats(self) -> dict:
        """
        è·å–èŠå¤©ä¼šè¯ç»Ÿè®¡ä¿¡æ¯
        :return: ä¼šè¯ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            chat_manager = get_chat_duckdb_manager()
            return {
                "active_chat_count": chat_manager.get_active_chat_count(),
                "chat_list": chat_manager.get_chat_list(),
            }
        except Exception as e:
            logger.error(f"è·å–èŠå¤©ä¼šè¯ç»Ÿè®¡å¤±è´¥: {str(e)}")
            return {"active_chat_count": 0, "chat_list": []}

    @staticmethod
    def _format_multi_file_table_info(state: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–å¤šæ–‡ä»¶å¤šSheetä¿¡æ¯ä¸ºHTMLæ ¼å¼
        :param state: çŠ¶æ€å­—å…¸
        :return: æ ¼å¼åŒ–åçš„HTMLå­—ç¬¦ä¸²
        """
        file_metadata = state.get("file_metadata", {})
        sheet_metadata = state.get("sheet_metadata", {})
        db_info = state.get("db_info", [])

        if not file_metadata and not db_info:
            return "æœªæ‰¾åˆ°æ–‡ä»¶ä¿¡æ¯"

        html_content = """
        æ–‡ä»¶è§£æç»“æœ<br>
        """

        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
        if file_metadata:
            html_content += "æ–‡ä»¶åˆ—è¡¨ï¼š<br><ol>"
            for file_key, file_info in file_metadata.items():
                html_content += f"<li>file_name: {file_info.file_name}  |"
                f"Catalog: {file_info.catalog_name} |"
                f"Sheets: {file_info.sheet_count} |"
                f"ä¸Šä¼ æ—¶é—´: {file_info.upload_time} </li>"
            html_content += "</ol><br>"

        # æ˜¾ç¤ºè¡¨ä¿¡æ¯
        if db_info:
            html_content += "æ•°æ®è¡¨ï¼š<br><ol>"
            for table in db_info:
                table_name = table.get("table_name", "æœªçŸ¥è¡¨")
                table_comment = table.get("table_comment", "")
                columns = table.get("columns", {})
                html_content += (
                    f"<li>table_name:{table_name} | table_comment:{table_comment} | åˆ—æ•°: {len(columns)} </li>"
                )

            html_content += "</ol><br>"

        html_content += "<br>"
        return html_content

    @staticmethod
    def _format_sql_generator_output(step_value: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ– SQL ç”Ÿæˆå™¨è¾“å‡ºä¸º JSON ä»£ç å—æ ¼å¼
        """
        # ä¼˜å…ˆä½¿ç”¨ä¿å­˜çš„å®Œæ•´ JSON å“åº”
        sql_response_json = step_value.get("sql_response_json")
        
        if sql_response_json:
            # å°†å®Œæ•´çš„ JSON å“åº”æ ¼å¼åŒ–ä¸º markdown ä»£ç å—
            json_str = json.dumps(sql_response_json, ensure_ascii=False, indent=2)
            return f"```json\n{json_str}\n```"
        
        # å¦‚æœæ²¡æœ‰ä¿å­˜çš„ JSONï¼Œä»ç°æœ‰å­—æ®µæ„å»º
        generated_sql = step_value.get("generated_sql", "")
        chart_type = step_value.get("chart_type", "")
        used_tables = step_value.get("used_tables", [])
        
        if not generated_sql or generated_sql == "No SQL query generated":
            return "```json\n{\n  \"success\": false,\n  \"message\": \"SQL ç”Ÿæˆå¤±è´¥\"\n}\n```"
        
        # æ„å»º JSON å“åº”
        sql_response = {
            "success": True,
            "sql": generated_sql,
            "tables": used_tables if used_tables else [],
            "chart-type": chart_type if chart_type else "table"
        }
        
        json_str = json.dumps(sql_response, ensure_ascii=False, indent=2)
        return f"```json\n{json_str}\n```"
    
    @staticmethod
    def _format_chart_generator_output(step_value: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–å›¾è¡¨ç”Ÿæˆå™¨è¾“å‡ºä¸º JSON ä»£ç å—æ ¼å¼
        """
        chart_config = step_value.get("chart_config")
        
        if not chart_config:
            return "å›¾è¡¨é…ç½®ç”Ÿæˆå®Œæˆ"
        
        # å°†å›¾è¡¨é…ç½®æ ¼å¼åŒ–ä¸º JSON ä»£ç å—
        if isinstance(chart_config, dict):
            config_json = json.dumps(chart_config, ensure_ascii=False, indent=2)
            return f"```json\n{config_json}\n```"
        else:
            return f"```json\n{str(chart_config)}\n```"
    
    @staticmethod
    def _format_execution_result(execution_result) -> str:
        """
        æ ¼å¼åŒ–SQLæ‰§è¡Œç»“æœ
        :param execution_result: ExecutionResultå¯¹è±¡
        :return: æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
        """
        if not execution_result:
            return "æœªæ‰¾åˆ°æ‰§è¡Œç»“æœ"

        if execution_result.success:
            row_count = len(execution_result.data) if execution_result.data else 0
            column_count = len(execution_result.columns) if execution_result.columns else 0
            return f"âœ… æŸ¥è¯¢æ‰§è¡ŒæˆåŠŸï¼è¿”å› {row_count} è¡Œæ•°æ®ï¼Œ{column_count} åˆ—"
        else:
            return f"âŒ æŸ¥è¯¢æ‰§è¡Œå¤±è´¥ï¼š{execution_result.error or 'æœªçŸ¥é”™è¯¯'}"

    @staticmethod
    def _format_table_columns_info(db_info: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–è¡¨æ ¼åˆ—ä¿¡æ¯ä¸ºHTML detailsæ ‡ç­¾æ ¼å¼
        :param db_info: æ•°æ®åº“ä¿¡æ¯å­—å…¸
        :return: æ ¼å¼åŒ–åçš„HTMLå­—ç¬¦ä¸²
        """
        db_info = db_info["db_info"]
        if not db_info or "columns" not in db_info:
            return ""

        columns_info = db_info["columns"]

        html_content = """
        <ul>
        """
        for column_name, column_details in columns_info.items():
            comment = column_details.get("comment", column_name)
            type_ = column_details.get("type", "æœªçŸ¥")
            html_content += f"<li><strong>{column_name}</strong>: {comment} (ç±»å‹: {type_})</li>\n"

        html_content += """</ul>"""

        return html_content
