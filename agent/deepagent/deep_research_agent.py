import asyncio
import json
import logging
import os
import re
import traceback
import ast
from typing import Optional

from deepagents import create_deep_agent
from langchain_core.messages import HumanMessage
from langgraph.checkpoint.memory import InMemorySaver

from agent.deepagent.tools import search_web
from common.llm_util import get_llm
from common.minio_util import MinioUtils
from constants.code_enum import DataTypeEnum, IntentEnum
from services.user_service import add_user_record, decode_jwt_token
from langfuse import get_client
from langfuse.langchain import CallbackHandler

logger = logging.getLogger(__name__)

minio_utils = MinioUtils()

current_dir = os.path.dirname(os.path.abspath(__file__))


class DeepAgent:
    """
    åŸºäºDeepAgentsçš„æ™ºèƒ½ä½“ï¼Œæ”¯æŒå¤šè½®å¯¹è¯è®°å¿†
    """

    def __init__(self):

        # å…¨å±€checkpointerç”¨äºæŒä¹…åŒ–æ‰€æœ‰ç”¨æˆ·çš„å¯¹è¯çŠ¶æ€
        self.checkpointer = InMemorySaver()

        # æ˜¯å¦å¯ç”¨é“¾è·¯è¿½è¸ª
        self.ENABLE_TRACING = os.getenv("LANGFUSE_TRACING_ENABLED", "true").lower() == "true"

        # å­˜å‚¨è¿è¡Œä¸­çš„ä»»åŠ¡
        self.running_tasks = {}

        # === é…ç½®å‚æ•° ===
        self.RECURSION_LIMIT = int(os.getenv("RECURSION_LIMIT", 25))

        # === åŠ è½½æ ¸å¿ƒæŒ‡ä»¤ ===
        # ä» instructions.md æ–‡ä»¶è¯»å–ç³»ç»Ÿæç¤ºè¯
        with open(os.path.join(current_dir, "instructions.md"), "r", encoding="utf-8") as f:
            self.CORE_INSTRUCTIONS = f.read()

        # === åŠ è½½å­æ™ºèƒ½ä½“é…ç½® ===
        # ä» subagents.json æ–‡ä»¶è¯»å–å„ä¸ªå­æ™ºèƒ½ä½“çš„è§’è‰²å®šä¹‰
        with open(os.path.join(current_dir, "subagents.json"), "r", encoding="utf-8") as f:
            self.subagents_config = json.load(f)

        # æå–ä¸‰ä¸ªå­æ™ºèƒ½ä½“çš„é…ç½®
        self.planner = self.subagents_config["planner"]  # è§„åˆ’å¸ˆ ä½¿ç”¨é»˜è®¤çš„
        self.researcher = self.subagents_config["researcher"]  # ç ”ç©¶å‘˜
        self.analyst = self.subagents_config["analyst"]  # åˆ†æå¸ˆ

        # å®šä¹‰æ™ºèƒ½ä½“å¯ä»¥ä½¿ç”¨çš„å·¥å…·
        self.tools = [search_web]

    @staticmethod
    def _create_response(
        content: str, message_type: str = "continue", data_type: str = DataTypeEnum.ANSWER.value[0]
    ) -> str:
        """å°è£…å“åº”ç»“æ„"""
        res = {
            "data": {"messageType": message_type, "content": content},
            "dataType": data_type,
        }
        return "data:" + json.dumps(res, ensure_ascii=False) + "\n\n"

    async def run_agent(
        self,
        query: str,
        response,
        session_id: Optional[str] = None,
        uuid_str: str = None,
        user_token=None,
        file_list: dict = None,
    ):
        """
        è¿è¡Œæ™ºèƒ½ä½“ï¼Œæ”¯æŒå¤šè½®å¯¹è¯è®°å¿†å’Œå®æ—¶æ€è€ƒè¿‡ç¨‹è¾“å‡º
        :param query: ç”¨æˆ·è¾“å…¥
        :param response: å“åº”å¯¹è±¡
        :param session_id: ä¼šè¯IDï¼Œç”¨äºåŒºåˆ†åŒä¸€è½®å¯¹è¯
        :param uuid_str: è‡ªå®šä¹‰IDï¼Œç”¨äºå”¯ä¸€æ ‡è¯†ä¸€æ¬¡é—®ç­”
        :param file_list: é™„ä»¶
        :param user_token: ç”¨æˆ·ä»¤ç‰Œ
        :return:
        """
        # è·å–ç”¨æˆ·ä¿¡æ¯ æ ‡è¯†å¯¹è¯çŠ¶æ€
        user_dict = await decode_jwt_token(user_token)
        task_id = user_dict["id"]
        task_context = {"cancelled": False}
        self.running_tasks[task_id] = task_context

        try:
            t02_answer_data = []

            # ä½¿ç”¨ç”¨æˆ·ä¼šè¯IDä½œä¸ºthread_idï¼Œå¦‚æœæœªæä¾›åˆ™ä½¿ç”¨é»˜è®¤å€¼
            thread_id = session_id if session_id else "default_thread"
            config = {"configurable": {"thread_id": thread_id}, "recursion_limit": 50}

            # å‡†å¤‡ tracing é…ç½®
            if self.ENABLE_TRACING:
                langfuse_handler = CallbackHandler()
                callbacks = [langfuse_handler]
                config["callbacks"] = callbacks
                config["metadata"] = {"langfuse_session_id": session_id}

            # å‘é€å¼€å§‹æ¶ˆæ¯
            start_msg = "ğŸ” **å¼€å§‹åˆ†æé—®é¢˜...**\n\n"
            await response.write(self._create_response(start_msg, "info"))
            t02_answer_data.append(start_msg)

            agent = create_deep_agent(
                tools=self.tools,  # å¯ç”¨å·¥å…·åˆ—è¡¨
                system_prompt=self.CORE_INSTRUCTIONS,  # ç³»ç»Ÿæç¤ºè¯
                subagents=[self.researcher, self.analyst],
                model=get_llm(),
                backend=self.checkpointer,
            ).with_config({"recursion_limit": self.RECURSION_LIMIT})

            # å¦‚æœæœ‰æ–‡ä»¶å†…å®¹ï¼Œåˆ™å°†å…¶æ·»åŠ åˆ°æŸ¥è¯¢ä¸­
            formatted_query = query

            # å‡†å¤‡æµå¼å¤„ç†å‚æ•°
            stream_args = {
                "input": {"messages": [HumanMessage(content=formatted_query)]},
                "config": config,
                "stream_mode": "messages",
            }

            # å¦‚æœå¯ç”¨ tracingï¼ŒåŒ…è£¹åœ¨ trace ä¸Šä¸‹æ–‡ä¸­
            if self.ENABLE_TRACING:
                langfuse = get_client()
                with langfuse.start_as_current_observation(
                    input=query,
                    as_type="agent",
                    name="æ·±åº¦æœç´¢",
                ) as rootspan:
                    user_info = await decode_jwt_token(user_token)
                    user_id = user_info.get("id")
                    rootspan.update_trace(session_id=session_id, user_id=user_id)
                    await self._stream_agent_response(
                        agent,
                        stream_args,
                        response,
                        task_id,
                        t02_answer_data,
                        uuid_str,
                        session_id,
                        query,
                        file_list,
                        user_token,
                    )
            else:
                await self._stream_agent_response(
                    agent,
                    stream_args,
                    response,
                    task_id,
                    t02_answer_data,
                    uuid_str,
                    session_id,
                    query,
                    file_list,
                    user_token,
                )

        except asyncio.CancelledError:
            await response.write(self._create_response("\n> âš ï¸ ä»»åŠ¡å·²è¢«å–æ¶ˆ", "info", DataTypeEnum.ANSWER.value[0]))
            await response.write(self._create_response("", "end", DataTypeEnum.STREAM_END.value[0]))
        except Exception as e:
            logger.error(f"Agentè¿è¡Œå¼‚å¸¸: {e}")
            traceback.print_exception(e)
            error_msg = f"âŒ **é”™è¯¯**: æ™ºèƒ½ä½“è¿è¡Œå¼‚å¸¸\n\n```\n{str(e)}\n```\n"
            await response.write(self._create_response(error_msg, "error", DataTypeEnum.ANSWER.value[0]))
        finally:
            # æ¸…ç†ä»»åŠ¡è®°å½•
            if task_id in self.running_tasks:
                del self.running_tasks[task_id]

    async def _stream_agent_response(
        self, agent, stream_args, response, task_id, t02_answer_data, uuid_str, session_id, query, file_list, user_token
    ):
        """å¤„ç†agentæµå¼å“åº”çš„æ ¸å¿ƒé€»è¾‘"""
        plan_task_mesage = False
        async for message_chunk, metadata in agent.astream(**stream_args):
            # print(metadata)
            # print(message_chunk)
            # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
            if self.running_tasks[task_id]["cancelled"]:
                await response.write(
                    self._create_response("\n> âš ï¸ ä»»åŠ¡å·²è¢«ç”¨æˆ·å–æ¶ˆ", "info", DataTypeEnum.ANSWER.value[0])
                )
                await response.write(self._create_response("", "end", DataTypeEnum.STREAM_END.value[0]))
                break

            # è·å–å½“å‰èŠ‚ç‚¹ä¿¡æ¯
            node_name = metadata.get("langgraph_node", "unknown")

            # å·¥å…·è°ƒç”¨è¾“å‡º
            if node_name == "tools":
                tool_name = message_chunk.name or "æœªçŸ¥å·¥å…·"

                if tool_name == "write_todos":
                    if not plan_task_mesage:
                        plan_markdown_str, plan_markdown_list = self.extract_content_as_markdown_list(
                            message_chunk.content
                        )
                        think_html = f"""<details style="color:gray;background-color: #f8f8f8;padding: 2px;border-radius: 
                                          6px;margin-top:5px;">
                                                <summary>{query}-ä»»åŠ¡è§„åˆ’å¦‚ä¸‹:\n</summary>"""
                        think_html += f"""{plan_markdown_str}"""
                        think_html += """</details>\n\n"""
                        await response.write(self._create_response(think_html, "info"))
                        t02_answer_data.append(think_html)
                        plan_task_mesage = True

                if tool_name == "search_web":
                    search_content = message_chunk.content
                    content_json = json.loads(search_content)
                    think_html = f"""\n > âœ… æœç´¢{content_json["query"]}\n\n"""
                    await response.write(self._create_response(think_html, "info"))
                    t02_answer_data.append(think_html)

                continue

            # è¾“å‡ºæ™ºèƒ½ä½“çš„æ€è€ƒå’Œå›ç­”å†…å®¹
            if message_chunk.content:
                content = message_chunk.content
                t02_answer_data.append(content)
                await response.write(self._create_response(content))

                # ç¡®ä¿å®æ—¶è¾“å‡º
                if hasattr(response, "flush"):
                    await response.flush()
                await asyncio.sleep(0)

        # å‘é€å®Œæˆæ¶ˆæ¯
        if not self.running_tasks[task_id]["cancelled"]:
            completion_msg = "\n\n---\n\nâœ¨ **æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼**\n"
            await response.write(self._create_response(completion_msg, "info"))
            t02_answer_data.append(completion_msg)

            # ä¿å­˜è®°å½•
            await add_user_record(
                uuid_str,
                session_id,
                query,
                t02_answer_data,
                {},
                IntentEnum.REPORT_QA.value[0],
                user_token,
                file_list,
            )

    @staticmethod
    def extract_content_as_markdown_list(text: str) -> tuple[Optional[str], list]:
        """
        å®‰å…¨åœ°ä»ç±» JSON å­—ç¬¦ä¸²ä¸­æå– content å­—æ®µï¼Œç”Ÿæˆçº¯ Markdown åˆ—è¡¨ã€‚
        ä½¿ç”¨ JSON è§£æï¼ˆè€Œé ast.literal_evalï¼‰ï¼Œæ›´ç¬¦åˆå®‰å…¨è§„èŒƒã€‚
        """
        # 1. æå– [...] åŒºåŸŸ
        match = re.search(r"\[.*\]", text, re.DOTALL)
        if not match:
            return None
        raw_list_str = match.group(0).strip()
        try:
            json_str = raw_list_str.replace("'", '"').replace('""', '"')

            todo_list = json.loads(json_str)

        except (json.JSONDecodeError, ValueError):
            return None

        if not isinstance(todo_list, list):
            return None

        lines = []
        for index, item in enumerate(todo_list, 1):  # ä»1å¼€å§‹ç¼–å·
            if isinstance(item, dict) and isinstance(item.get("content"), str):
                if index == 1:
                    lines.append(f"  {index}. {item['content']}")  # åœ¨ç¼–å·å‰æ·»åŠ ç©ºæ ¼
                else:
                    lines.append(f" {index}. {item['content']}")  # åœ¨ç¼–å·å‰æ·»åŠ ç©ºæ ¼

        return "\n\n".join(lines), lines

    async def cancel_task(self, task_id: str) -> bool:
        """
        å–æ¶ˆæŒ‡å®šçš„ä»»åŠ¡
        :param task_id: ä»»åŠ¡ID
        :return: æ˜¯å¦æˆåŠŸå–æ¶ˆ
        """
        if task_id in self.running_tasks:
            self.running_tasks[task_id]["cancelled"] = True
            return True
        return False

    def get_running_tasks(self):
        """
        è·å–å½“å‰è¿è¡Œä¸­çš„ä»»åŠ¡åˆ—è¡¨
        :return: è¿è¡Œä¸­çš„ä»»åŠ¡åˆ—è¡¨
        """
        return list(self.running_tasks.keys())
