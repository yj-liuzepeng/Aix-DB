import asyncio
import json
import logging
import os
import time
import uuid
from typing import Dict, Any, Optional, Union

from langgraph.graph.state import CompiledStateGraph

from agent.text2sql.analysis.graph import create_graph
from agent.text2sql.state.agent_state import AgentState
from constants.code_enum import DataTypeEnum, IntentEnum
from services.user_service import add_user_record, decode_jwt_token
from langfuse import get_client
from langfuse.langchain import CallbackHandler

logger = logging.getLogger(__name__)

# æ­¥éª¤åç§°æ˜ å°„ï¼ˆä¸­æ–‡ï¼‰
STEP_NAME_MAP = {
    "schema_inspector": "è¡¨ç»“æ„æ£€ç´¢...",
    "table_relationship": "è¡¨å…³ç³»åˆ†æ...",
    "early_recommender": "æ¨èé—®é¢˜ç”Ÿæˆ...",
    "sql_generator": "SQLç”Ÿæˆ...",
    "permission_filter": "æƒé™è¿‡æ»¤...",
    "sql_executor": "SQLæ‰§è¡Œ...",
    "chart_generator": "å›¾è¡¨é…ç½®...",
    "summarize": "ç»“æœæ€»ç»“...",
    "parallel_collector": "å¹¶è¡Œå¤„ç†ï¼ˆå›¾è¡¨é…ç½®ä¸ç»“æœæ€»ç»“ï¼‰...",
    "unified_collector": "ç»Ÿä¸€æ”¶é›†ï¼ˆç»“æœæ€»ç»“â†’å›¾è¡¨æ•°æ®â†’æ¨èé—®é¢˜ï¼‰...",
    "data_render": "æ•°æ®æ¸²æŸ“...",
    "question_recommender": "æ¨èé—®é¢˜...",
    "datasource_selector": "æ•°æ®æºé€‰æ‹©...",
    "error_handler": "é”™è¯¯å¤„ç†",
}


class Text2SqlAgent:
    """
    æ–‡æœ¬è¯­è¨€è½¬SQLä»£ç†
    """

    def __init__(self):
        # å­˜å‚¨è¿è¡Œä¸­çš„ä»»åŠ¡
        self.running_tasks = {}
        # è·å–ç¯å¢ƒå˜é‡æ§åˆ¶æ˜¯å¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼Œé»˜è®¤ä¸ºå¼€å¯
        self.show_thinking_process = os.getenv("SHOW_THINKING_PROCESS", "true").lower() == "true"
        # æ˜¯å¦å¯ç”¨é“¾è·¯è¿½è¸ª
        self.ENABLE_TRACING = os.getenv("LANGFUSE_TRACING_ENABLED", "true").lower() == "true"
        # å­˜å‚¨æ­¥éª¤å¼€å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—è€—æ—¶ï¼‰
        self.step_start_times = {}
        # å­˜å‚¨æ­¥éª¤çš„ progressId
        self.step_progress_ids = {}

    async def run_agent(
        self,
        query: str,
        response=None,
        chat_id: str = None,
        uuid_str: str = None,
        user_token=None,
        datasource_id: int = None,
    ) -> None:
        """
        è¿è¡Œæ™ºèƒ½ä½“
        :param query: ç”¨æˆ·è¾“å…¥
        :param response: å“åº”å¯¹è±¡
        :param chat_id: ä¼šè¯IDï¼Œç”¨äºåŒºåˆ†åŒä¸€è½®å¯¹è¯
        :param uuid_str: è‡ªå®šä¹‰IDï¼Œç”¨äºå”¯ä¸€æ ‡è¯†ä¸€æ¬¡é—®ç­”
        :param user_token: ç”¨æˆ·ç™»å½•çš„token
        :param datasource_id: æ•°æ®æºID
        :return: None
        """
        t02_answer_data = []
        t04_answer_data = {}
        current_step = None
        final_filtered_sql = ""  # ç”¨äºä¿å­˜æœ€ç»ˆçš„SQLè¯­å¥

        try:
            # è·å–ç”¨æˆ·ä¿¡æ¯ï¼ˆåªè°ƒç”¨ä¸€æ¬¡ï¼‰
            user_dict = await decode_jwt_token(user_token)
            user_id = user_dict.get("id", 1)  # é»˜è®¤ä¸ºç®¡ç†å‘˜
            task_id = user_dict["id"]
            
            initial_state = AgentState(
                user_query=query,
                attempts=0,
                correct_attempts=0,
                datasource_id=datasource_id,
                user_id=user_id
            )
            
            # æ£€æŸ¥æ•°æ®æºæƒé™ï¼ˆå¦‚æœæŒ‡å®šäº† datasource_idï¼‰
            # æƒé™æ£€æŸ¥ç»“æœä¼šé€šè¿‡ datasource_selector èŠ‚ç‚¹å¤„ç†ï¼Œç»Ÿä¸€é€šè¿‡ error_handler èŠ‚ç‚¹æµå¼è¾“å‡º
            if datasource_id:
                from model.db_connection_pool import get_db_pool
                from model.datasource_models import DatasourceAuth
                from common.permission_util import is_admin
                from sqlalchemy import and_
                
                db_pool = get_db_pool()
                with db_pool.get_session() as session:
                    # ç®¡ç†å‘˜è·³è¿‡æƒé™æ£€æŸ¥
                    if not is_admin(user_id):
                        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰è¯¥æ•°æ®æºçš„æƒé™
                        auth = session.query(DatasourceAuth).filter(
                            and_(
                                DatasourceAuth.datasource_id == datasource_id,
                                DatasourceAuth.user_id == user_id,
                                DatasourceAuth.enable == True
                            )
                        ).first()
                        
                        if not auth:
                            # æ— æƒé™ï¼Œè®¾ç½®é”™è¯¯æ¶ˆæ¯ï¼Œè®© error_handler èŠ‚ç‚¹ç»Ÿä¸€å¤„ç†
                            error_msg = "æ‚¨æ²¡æœ‰è®¿é—®è¯¥æ•°æ®æºçš„æƒé™ï¼Œè¯·è”ç³»ç®¡ç†å‘˜æˆæƒã€‚"
                            logger.warning(f"ç”¨æˆ· {user_id} å°è¯•è®¿é—®æœªæˆæƒçš„æ•°æ®æº {datasource_id}")
                            initial_state["error_message"] = error_msg
                            initial_state["datasource_id"] = None  # æ¸…ç©º datasource_idï¼Œè®©æµç¨‹è¿›å…¥ error_handler
            graph: CompiledStateGraph = create_graph(datasource_id)

            # æ ‡è¯†å¯¹è¯çŠ¶æ€
            task_context = {"cancelled": False}
            self.running_tasks[task_id] = task_context

            # å‡†å¤‡ tracing é…ç½®
            config = {}
            if self.ENABLE_TRACING:
                langfuse_handler = CallbackHandler()
                callbacks = [langfuse_handler]
                config = {
                    "callbacks": callbacks,
                    "metadata": {
                        "langfuse_session_id": chat_id,
                    },
                }

            # å¼‚æ­¥æµå¼æ‰§è¡Œ
            stream_kwargs = {
                "input": initial_state,
                "stream_mode": "updates",
                "config": config,
            }

            # å¦‚æœå¯ç”¨ tracingï¼ŒåŒ…è£¹åœ¨ trace ä¸Šä¸‹æ–‡ä¸­
            if self.ENABLE_TRACING:
                langfuse = get_client()
                with langfuse.start_as_current_observation(
                    input=query,
                    as_type="agent",
                    name="æ•°æ®é—®ç­”",
                ) as rootspan:
                    # ä½¿ç”¨ä¹‹å‰è·å–çš„ user_idï¼Œé¿å…é‡å¤è°ƒç”¨
                    rootspan.update_trace(session_id=chat_id, user_id=user_id)

                    async for chunk_dict in graph.astream(**stream_kwargs):
                        current_step, t02_answer_data = await self._process_chunk(
                            chunk_dict, response, task_id, current_step, t02_answer_data, t04_answer_data
                        )
                        # è·Ÿè¸ªpermission_filterèŠ‚ç‚¹åçš„SQLè¯­å¥
                        if "permission_filter" in chunk_dict:
                            step_value = chunk_dict.get("permission_filter", {})
                            filtered_sql = step_value.get("filtered_sql")
                            if filtered_sql:
                                final_filtered_sql = filtered_sql
            else:
                async for chunk_dict in graph.astream(**stream_kwargs):
                    current_step, t02_answer_data = await self._process_chunk(
                        chunk_dict, response, task_id, current_step, t02_answer_data, t04_answer_data
                    )
                    # è·Ÿè¸ªpermission_filterèŠ‚ç‚¹åçš„SQLè¯­å¥
                    if "permission_filter" in chunk_dict:
                        step_value = chunk_dict.get("permission_filter", {})
                        filtered_sql = step_value.get("filtered_sql")
                        if filtered_sql:
                            final_filtered_sql = filtered_sql

            # æµç»“æŸæ—¶å…³é—­æœ€åçš„detailsæ ‡ç­¾
            if self.show_thinking_process:
                if current_step is not None and current_step not in ["summarize", "data_render", "error_handler"]:
                    await self._close_current_step(response, t02_answer_data)

            # åªæœ‰åœ¨æœªå–æ¶ˆçš„æƒ…å†µä¸‹æ‰ä¿å­˜è®°å½•
            if not self.running_tasks[task_id]["cancelled"]:
                record_id = await add_user_record(
                    uuid_str,
                    chat_id,
                    query,
                    t02_answer_data,
                    t04_answer_data,
                    IntentEnum.DATABASE_QA.value[0],
                    user_token,
                    {},
                    datasource_id,
                    final_filtered_sql,  # ä¼ é€’SQLè¯­å¥
                )
                # å‘é€record_idåˆ°å‰ç«¯ï¼Œç”¨äºå®æ—¶å¯¹è¯æ—¶æ˜¾ç¤ºSQLå›¾æ ‡
                if record_id and response:
                    await self._send_response(
                        response=response,
                        content={"record_id": record_id},
                        data_type=DataTypeEnum.RECORD_ID.value[0]
                    )

        except asyncio.CancelledError:
            await response.write(self._create_response("\n> è¿™æ¡æ¶ˆæ¯å·²åœæ­¢", "info", DataTypeEnum.ANSWER.value[0]))
            await response.write(self._create_response("", "end", DataTypeEnum.STREAM_END.value[0]))
        except Exception as e:
            logger.error(f"Error in run_agent: {str(e)}", exc_info=True)
            error_msg = f"å¤„ç†è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"
            await self._send_response(response, error_msg, "error")

    async def _process_chunk(
        self,
        chunk_dict,
        response,
        task_id,
        current_step,
        t02_answer_data,
        t04_answer_data,
    ):
        """
        å¤„ç†å•ä¸ªæµå¼å—æ•°æ®
        """
        # æ£€æŸ¥æ˜¯å¦å·²å–æ¶ˆ
        if task_id in self.running_tasks and self.running_tasks[task_id]["cancelled"]:
            if self.show_thinking_process:
                await self._send_response(response, "</details>\n\n", "continue", DataTypeEnum.ANSWER.value[0])
            await response.write(self._create_response("\n> è¿™æ¡æ¶ˆæ¯å·²åœæ­¢", "info", DataTypeEnum.ANSWER.value[0]))
            # å‘é€æœ€ç»ˆåœæ­¢ç¡®è®¤æ¶ˆæ¯
            await response.write(self._create_response("", "end", DataTypeEnum.STREAM_END.value[0]))
            raise asyncio.CancelledError()

        langgraph_step, step_value = next(iter(chunk_dict.items()))

        # å¤„ç†æ­¥éª¤å˜æ›´
        current_step, t02_answer_data = await self._handle_step_change(
            response, current_step, langgraph_step, t02_answer_data
        )

        # å¤„ç†å…·ä½“æ­¥éª¤å†…å®¹
        if step_value:
            await self._process_step_content(response, langgraph_step, step_value, t02_answer_data, t04_answer_data)
        
        # æ‰€æœ‰æ­¥éª¤éƒ½å‘é€å®Œæˆä¿¡æ¯ï¼ˆæ— è®ºæ˜¯å¦æœ‰ step_valueï¼‰
        if langgraph_step in self.step_progress_ids:
            progress_id = self.step_progress_ids.get(langgraph_step)
            if progress_id:
                step_name_cn = STEP_NAME_MAP.get(langgraph_step, langgraph_step)
                await self._send_step_progress(
                    response=response,
                    step=langgraph_step,
                    step_name=step_name_cn,
                    status="complete",
                    progress_id=progress_id,
                )
                # æ¸…ç†å·²å®Œæˆçš„æ­¥éª¤ progressId
                del self.step_progress_ids[langgraph_step]

        return current_step, t02_answer_data

    async def _handle_step_change(
        self,
        response,
        current_step: Optional[str],
        new_step: str,
        t02_answer_data: list,
    ) -> tuple:
        """
        å¤„ç†æ­¥éª¤å˜æ›´
        """
        # è®°å½•æ–°æ­¥éª¤å¼€å§‹æ—¶é—´ï¼ˆç”¨äºè®¡ç®—è€—æ—¶ï¼‰
        if new_step and new_step not in self.step_start_times:
            self.step_start_times[new_step] = time.perf_counter()
            logger.debug(f"æ­¥éª¤ {new_step} å¼€å§‹")
            
            # ç”Ÿæˆæ–°çš„ progressId å¹¶å‘é€æ­¥éª¤å¼€å§‹ä¿¡æ¯
            progress_id = str(uuid.uuid4())
            self.step_progress_ids[new_step] = progress_id
            step_name_cn = STEP_NAME_MAP.get(new_step, new_step)
            await self._send_step_progress(
                response=response,
                step=new_step,
                step_name=step_name_cn,
                status="start",
                progress_id=progress_id,
            )
        
        if self.show_thinking_process:
            if new_step != current_step:
                # å¦‚æœä¹‹å‰æœ‰æ‰“å¼€çš„æ­¥éª¤ï¼Œå…ˆå…³é—­å®ƒ
                if current_step is not None and current_step not in ["summarize", "data_render", "error_handler"]:
                    await self._close_current_step(response, t02_answer_data)

                # æ‰“å¼€æ–°çš„æ­¥éª¤ (é™¤äº† summarizeã€data_renderã€unified_collector å’Œ error_handler) think_html æ ‡ç­¾é‡Œé¢æ·»åŠ openå±æ€§æ§åˆ¶æ€è€ƒè¿‡ç¨‹æ˜¯å¦é»˜è®¤å±•å¼€æ˜¾ç¤º
                # error_handler æ˜¯å¼‚å¸¸èŠ‚ç‚¹ï¼Œç›´æ¥æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼Œä¸éœ€è¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹æ ‡ç­¾
                # datasource_selectorã€early_recommenderã€unified_collector ä¹Ÿä¸å±•ç¤ºæ€è€ƒè¿‡ç¨‹
                if new_step not in [
                    "summarize",
                    "data_render",
                    "error_handler",
                    "datasource_selector",
                    "early_recommender",
                    "unified_collector",
                    "question_recommender",
                ]:
                    think_html = f"""<details style="color:gray;background-color: #f8f8f8;padding: 2px;border-radius: 
                    6px;margin-top:5px;">
                                 <summary>{new_step}...</summary>"""
                    await self._send_response(response, think_html, "continue", "t02")
                    t02_answer_data.append(think_html)
        else:
            # å¦‚æœä¸æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼Œåˆ™åªå¤„ç†ç‰¹å®šçš„æ­¥éª¤
            if new_step in ["summarize", "data_render", "error_handler"]:
                # å¯¹äºéœ€è¦æ˜¾ç¤ºçš„æ­¥éª¤ï¼Œç¡®ä¿ä¹‹å‰çš„æ­¥éª¤å·²å…³é—­
                if current_step is not None and current_step not in ["summarize", "data_render", "error_handler"]:
                    pass  # ä¸éœ€è¦å…³é—­detailsæ ‡ç­¾ï¼Œå› ä¸ºæˆ‘ä»¬æ ¹æœ¬æ²¡æœ‰æ‰“å¼€å®ƒ

        return new_step, t02_answer_data

    async def _close_current_step(self, response, t02_answer_data: list) -> None:
        """
        å…³é—­å½“å‰æ­¥éª¤çš„detailsæ ‡ç­¾
        """
        if self.show_thinking_process:
            close_tag = "</details>\n\n"
            await self._send_response(response, close_tag, "continue", "t02")
            t02_answer_data.append(close_tag)

    async def _process_step_content(
        self,
        response,
        step_name: str,
        step_value: Dict[str, Any],
        t02_answer_data: list,
        t04_answer_data: Dict[str, Any],
    ) -> None:
        """
        å¤„ç†å„ä¸ªæ­¥éª¤çš„å†…å®¹
        """
        # è®¡ç®—æ­¥éª¤è€—æ—¶ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
        elapsed_time = None
        if step_name in self.step_start_times:
            start_time = self.step_start_times[step_name]
            end_time = time.perf_counter()
            elapsed_time = end_time - start_time
            logger.debug(f"æ­¥éª¤ {step_name} è€—æ—¶: {elapsed_time:.3f}ç§’")
            del self.step_start_times[step_name]
        
        content_map = {
            # æ•°æ®æºå¼‚å¸¸èŠ‚ç‚¹ï¼šä»…è¾“å‡ºå‹å¥½çš„é”™è¯¯æç¤ºï¼Œä¸å†ç»§ç»­åç»­æ­¥éª¤
            "error_handler": lambda: step_value.get(
                "error_message",
                "å½“å‰æ²¡æœ‰å¯ç”¨çš„æ•°æ®æºï¼Œè¯·è”ç³»ç®¡ç†å‘˜ã€‚",
            ),
            "schema_inspector": lambda: self._format_db_info_with_bm25(step_value),
            "table_relationship": lambda: json.dumps(step_value["table_relationship"], ensure_ascii=False),
            "sql_generator": lambda: step_value["generated_sql"],
            # æƒé™è¿‡æ»¤èŠ‚ç‚¹ï¼šè¾“å‡ºæ³¨å…¥æƒé™åçš„ SQLï¼Œå¦‚æœæ²¡æœ‰åˆ™å›é€€åˆ°åŸå§‹ SQL
            "permission_filter": lambda: step_value.get("filtered_sql")
            or step_value.get("generated_sql", "No SQL query generated"),
            # SQL æ‰§è¡ŒèŠ‚ç‚¹ï¼šæˆåŠŸ/å¤±è´¥åˆ†åˆ«è¿”å›ä¸åŒä¿¡æ¯ï¼Œå¤±è´¥æ—¶æˆªå–ä¸€æ®µé”™è¯¯è¯¦æƒ…
            "sql_executor": lambda: self._format_sql_execution_message(step_value.get("execution_result")),
            # å›¾è¡¨ç”ŸæˆèŠ‚ç‚¹ï¼šè¾“å‡ºæœ€ç»ˆé€‰å®šçš„å›¾è¡¨ç±»å‹
            "chart_generator": lambda: self._format_chart_type_message(step_value),
            "summarize": lambda: step_value.get("report_summary", ""),
            "data_render": lambda: step_value.get("render_data", {}) if step_value.get("render_data") else {},  # è¿”å›å¯¹è±¡ï¼Œä¸æ˜¯ JSON å­—ç¬¦ä¸²
            # ç»Ÿä¸€æ”¶é›†èŠ‚ç‚¹ï¼šä¸åœ¨ content_map ä¸­å¤„ç†ï¼Œç”± _process_unified_collector ä¸“é—¨å¤„ç†
            # "unified_collector": lambda: self._format_unified_collector_message(step_value),
        }

        if step_name in content_map:
            content = content_map[step_name]()
            # å¯¹äº data_renderï¼Œcontent å·²ç»æ˜¯å¯¹è±¡ï¼Œä¸éœ€è¦æ·»åŠ å‰ç¼€

            # æ•°æ®æ¸²æŸ“èŠ‚ç‚¹è¿”å›ä¸šåŠ¡æ•°æ®
            data_type = (
                DataTypeEnum.BUS_DATA.value[0] if step_name == "data_render" else DataTypeEnum.ANSWER.value[0]
            )

            # æ ¹æ®ç¯å¢ƒå˜é‡å†³å®šæ˜¯å¦å‘é€æ­¥éª¤çš„å†…å®¹åˆ°å‰ç«¯
            # å½“ SHOW_THINKING_PROCESS å…³é—­æ—¶ï¼Œåªè¾“å‡º summarize æ­¥éª¤çš„å†…å®¹åˆ°å‰ç«¯
            # å½“ SHOW_THINKING_PROCESS å¼€å¯æ—¶ï¼Œè¾“å‡ºæ‰€æœ‰æ­¥éª¤çš„å†…å®¹åˆ°å‰ç«¯
            # unified_collector èŠ‚ç‚¹ç”±ä¸“é—¨çš„ _process_unified_collector å¤„ç†ï¼Œä¸åœ¨è¿™é‡Œå‘é€æ ¼å¼åŒ–æ¶ˆæ¯
            if self.show_thinking_process:
                # å¼€å¯æ€è€ƒè¿‡ç¨‹æ—¶ï¼Œå‘é€æ‰€æœ‰æ­¥éª¤çš„å†…å®¹ï¼ˆé™¤äº† unified_collectorï¼‰
                should_send = step_name != "unified_collector"
            else:
                # å…³é—­æ€è€ƒè¿‡ç¨‹æ—¶ï¼Œåªå‘é€ summarize æ­¥éª¤çš„å†…å®¹
                should_send = step_name == "summarize"

            if should_send:
                await self._send_response(response=response, content=content, data_type=data_type)

                # åªæœ‰å½“ show_thinking_process å¼€å¯æ—¶ï¼Œæˆ–è€…å½“å‰æ­¥éª¤æ˜¯ summarize æ—¶ï¼Œæ‰æ”¶é›†åˆ° t02_answer_data
                # å…³é—­æ€è€ƒè¿‡ç¨‹æ—¶ï¼Œåªä¿å­˜ summarize æ­¥éª¤çš„å†…å®¹åˆ°æ•°æ®åº“
                should_collect = self.show_thinking_process or step_name == "summarize"
                if should_collect and data_type == DataTypeEnum.ANSWER.value[0]:
                    t02_answer_data.append(content)

            # è¿™é‡Œè®¾ç½®æ¸²æŸ“æ•°æ®
            if step_name == "data_render" and data_type == DataTypeEnum.BUS_DATA.value[0]:
                render_data = step_value.get("render_data", {})
                t04_answer_data.clear()
                t04_answer_data.update({"data": render_data, "dataType": data_type})

            # å¯¹äºéæ¸²æŸ“æ­¥éª¤ï¼Œåˆ·æ–°å“åº”
            if step_name != "data_render":
                if hasattr(response, "flush"):
                    await response.flush()
                await asyncio.sleep(0)

        # å¤„ç†ç»Ÿä¸€æ”¶é›†èŠ‚ç‚¹ï¼šæŒ‰é¡ºåºæ¨é€ summarize â†’ å›¾è¡¨æ•°æ® â†’ æ¨èé—®é¢˜
        # æ³¨æ„ï¼šunified_collector èŠ‚ç‚¹ä¸åœ¨ content_map ä¸­å¤„ç†ï¼Œé¿å…å‘é€æ ¼å¼åŒ–æ¶ˆæ¯åˆ°å‰ç«¯
        if step_name == "unified_collector":
            await self._process_unified_collector(
                response, step_value, t02_answer_data, t04_answer_data
            )
            # å¤„ç†å®Œ unified_collector åç›´æ¥è¿”å›ï¼Œä¸å†é€šè¿‡ content_map å‘é€å†…å®¹
            return
        
        # å¤„ç†æ¨èé—®é¢˜ï¼šå°†æ¨èé—®é¢˜åˆå¹¶åˆ°å·²æœ‰çš„å›¾è¡¨æ•°æ®ä¸­å‘é€åˆ°å‰ç«¯ï¼ˆåœ¨ content_map ä¹‹å¤–å¤„ç†ï¼‰
        # æ³¨æ„ï¼šå¦‚æœä½¿ç”¨äº† unified_collectorï¼Œè¿™ä¸ªåˆ†æ”¯å¯èƒ½ä¸ä¼šæ‰§è¡Œ
        if step_name == "question_recommender":
            recommended_questions = step_value.get("recommended_questions", [])
            logger.info(
                f"question_recommender æ­¥éª¤: è·å–åˆ°æ¨èé—®é¢˜æ•°é‡: "
                f"{len(recommended_questions) if recommended_questions else 0}, "
                f"t04_answer_data: {t04_answer_data}"
            )

            if recommended_questions and isinstance(recommended_questions, list) and len(recommended_questions) > 0:
                # è·å–å·²æœ‰çš„å›¾è¡¨æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºæ–°çš„æ•°æ®ç»“æ„
                if (
                    t04_answer_data
                    and "data" in t04_answer_data
                    and isinstance(t04_answer_data["data"], dict)
                    and t04_answer_data["data"]
                ):
                    # å°†æ¨èé—®é¢˜æ·»åŠ åˆ°å·²æœ‰çš„å›¾è¡¨æ•°æ®ä¸­
                    t04_answer_data["data"]["recommended_questions"] = recommended_questions
                    payload = t04_answer_data["data"]
                    data_type = t04_answer_data.get("dataType", DataTypeEnum.BUS_DATA.value[0])
                else:
                    # å¦‚æœæ²¡æœ‰å›¾è¡¨æ•°æ®ï¼Œä»…ä½¿ç”¨æ¨èé—®é¢˜æ„å»ºæ•°æ®ç»“æ„
                    logger.warning(
                        f"question_recommender æ­¥éª¤: t04_answer_data ä¸ºç©ºæˆ–æ— æ•ˆï¼Œ"
                        f"t04_answer_data: {t04_answer_data}"
                    )
                    payload = {"recommended_questions": recommended_questions}
                    data_type = DataTypeEnum.BUS_DATA.value[0]
                    # åŒæ­¥æ›´æ–° t04_answer_dataï¼Œç¡®ä¿ä¼šè¢«ä¿å­˜åˆ°æ•°æ®åº“
                    t04_answer_data.clear()
                    t04_answer_data.update({"data": payload, "dataType": data_type})

                # æ— è®ºæ˜¯å¦æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹ï¼Œéƒ½æ¨é€æ¨èé—®é¢˜æ•°æ®åˆ°å‰ç«¯
                await self._send_response(
                    response=response,
                    content=payload,
                    data_type=data_type,
                )
                logger.info(
                    f"å·²å‘é€ {len(recommended_questions)} ä¸ªæ¨èé—®é¢˜åˆ°å‰ç«¯ï¼Œ"
                    f"å®Œæ•´æ•°æ®: {t04_answer_data}"
                )
            else:
                logger.warning(
                    f"question_recommender æ­¥éª¤: æ¨èé—®é¢˜ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯ï¼Œ"
                    f"recommended_questions: {recommended_questions}"
                )

    async def _process_unified_collector(
        self,
        response,
        step_value: Dict[str, Any],
        t02_answer_data: list,
        t04_answer_data: Dict[str, Any],
    ) -> None:
        """
        å¤„ç†ç»Ÿä¸€æ”¶é›†èŠ‚ç‚¹ï¼šæŒ‰é¡ºåºæ¨é€ summarize â†’ å›¾è¡¨æ•°æ® â†’ æ¨èé—®é¢˜
        
        è¦æ±‚ï¼š
        1. é¦–å…ˆæ¨é€ summarizeï¼ˆæ–‡æœ¬æ€»ç»“ï¼‰
        2. ç„¶åæ¨é€å›¾è¡¨æ•°æ®ï¼ˆrender_dataï¼‰
        3. æœ€åæ¨é€æ¨èé—®é¢˜ï¼ˆrecommended_questionsï¼‰
        """
        logger.info("ğŸ“¦ å¼€å§‹å¤„ç†ç»Ÿä¸€æ”¶é›†èŠ‚ç‚¹")
        
        # 1. æ¨é€ summarizeï¼ˆç»“æœæ€»ç»“ï¼‰
        report_summary = step_value.get("report_summary")
        if report_summary:
            logger.info("ğŸ“¤ æ¨é€ summarizeï¼ˆç»“æœæ€»ç»“ï¼‰")
            await self._send_response(
                response=response,
                content=report_summary,
                data_type=DataTypeEnum.ANSWER.value[0],
            )
            # æ”¶é›†åˆ° t02_answer_data
            if not self.show_thinking_process or True:  # æ€»æ˜¯æ”¶é›† summarize
                t02_answer_data.append(report_summary)
        
        # 2. æ¨é€å›¾è¡¨æ•°æ®ï¼ˆrender_dataï¼‰
        render_data = step_value.get("render_data", {})
        if render_data:
            logger.info("ğŸ“¤ æ¨é€å›¾è¡¨æ•°æ®")
            # æ›´æ–° t04_answer_data
            t04_answer_data.clear()
            t04_answer_data.update({"data": render_data, "dataType": DataTypeEnum.BUS_DATA.value[0]})
            
            # å‘é€å›¾è¡¨æ•°æ®
            await self._send_response(
                response=response,
                content=render_data,
                data_type=DataTypeEnum.BUS_DATA.value[0],
            )
        
        # 3. æ¨é€æ¨èé—®é¢˜ï¼ˆrecommended_questionsï¼‰
        recommended_questions = step_value.get("recommended_questions", [])
        if recommended_questions and isinstance(recommended_questions, list) and len(recommended_questions) > 0:
            logger.info(f"ğŸ“¤ æ¨é€æ¨èé—®é¢˜ï¼Œæ•°é‡: {len(recommended_questions)}")
            
            # å°†æ¨èé—®é¢˜æ·»åŠ åˆ°å·²æœ‰çš„å›¾è¡¨æ•°æ®ä¸­
            if t04_answer_data and "data" in t04_answer_data and isinstance(t04_answer_data["data"], dict):
                t04_answer_data["data"]["recommended_questions"] = recommended_questions
                payload = t04_answer_data["data"]
                data_type = t04_answer_data.get("dataType", DataTypeEnum.BUS_DATA.value[0])
            else:
                # å¦‚æœæ²¡æœ‰å›¾è¡¨æ•°æ®ï¼Œä»…ä½¿ç”¨æ¨èé—®é¢˜æ„å»ºæ•°æ®ç»“æ„
                payload = {"recommended_questions": recommended_questions}
                data_type = DataTypeEnum.BUS_DATA.value[0]
                t04_answer_data.clear()
                t04_answer_data.update({"data": payload, "dataType": data_type})
            
            # å‘é€æ¨èé—®é¢˜
            await self._send_response(
                response=response,
                content=payload,
                data_type=data_type,
            )
            logger.info(f"âœ… å·²å‘é€ {len(recommended_questions)} ä¸ªæ¨èé—®é¢˜åˆ°å‰ç«¯")
        else:
            logger.warning(f"âš ï¸ æ¨èé—®é¢˜ä¸ºç©ºæˆ–æ ¼å¼é”™è¯¯: {recommended_questions}")
        
        logger.info("âœ… ç»Ÿä¸€æ”¶é›†èŠ‚ç‚¹å¤„ç†å®Œæˆ")

    @staticmethod
    def _format_unified_collector_message(step_value: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–ç»Ÿä¸€æ”¶é›†èŠ‚ç‚¹çš„æ¶ˆæ¯ï¼ˆç”¨äºæ—¥å¿—æˆ–è°ƒè¯•ï¼‰
        """
        parts = []
        if step_value.get("report_summary"):
            parts.append("âœ… ç»“æœæ€»ç»“å·²ç”Ÿæˆ")
        if step_value.get("render_data"):
            parts.append("âœ… å›¾è¡¨æ•°æ®å·²ç”Ÿæˆ")
        if step_value.get("recommended_questions"):
            count = len(step_value.get("recommended_questions", []))
            parts.append(f"âœ… æ¨èé—®é¢˜å·²ç”Ÿæˆï¼ˆ{count} ä¸ªï¼‰")
        return " | ".join(parts) if parts else "ç»Ÿä¸€æ”¶é›†å®Œæˆ"

    @staticmethod
    def _format_sql_execution_message(execution_result: Any) -> str:
        """
        æ ¼å¼åŒ– SQL æ‰§è¡Œç»“æœä¿¡æ¯ï¼š
        - æˆåŠŸï¼šè¿”å›å›ºå®šæˆåŠŸæç¤º
        - å¤±è´¥ï¼šè¿”å›å¸¦æœ‰éƒ¨åˆ†é”™è¯¯ä¿¡æ¯çš„æç¤ºï¼Œé¿å…é”™è¯¯ä¿¡æ¯è¿‡é•¿
        """
        try:
            if not execution_result:
                return "æ‰§è¡Œsqlè¯­å¥å¤±è´¥"

            # ExecutionResult ä¸º pydantic BaseModelï¼Œç›´æ¥è®¿é—®å±æ€§
            success = getattr(execution_result, "success", False)
            if success:
                return "æ‰§è¡Œsqlè¯­å¥æˆåŠŸ"

            raw_error = getattr(execution_result, "error", "") or ""
            # æˆªå–å‰ 200 ä¸ªå­—ç¬¦ï¼Œé¿å…è¿”å›è¿‡é•¿
            snippet = raw_error.strip().replace("\n", " ").replace("\r", " ")
            max_len = 200
            if len(snippet) > max_len:
                snippet = snippet[:max_len] + "..."

            # æœ€ç»ˆè¿”å›ç»™å‰ç«¯çš„æç¤º
            return f"æ‰§è¡Œsqlè¯­å¥å¤±è´¥: {snippet}" if snippet else "æ‰§è¡Œsqlè¯­å¥å¤±è´¥"
        except Exception:
            # å…œåº•ï¼Œç»ä¸å› ä¸ºæ ¼å¼åŒ–é”™è¯¯å½±å“ä¸»æµç¨‹
            return "æ‰§è¡Œsqlè¯­å¥å¤±è´¥"

    def _format_db_info_with_bm25(self, step_value: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–æ•°æ®åº“ä¿¡æ¯ï¼Œå¹¶è¿½åŠ  BM25 åˆ†è¯è¯´æ˜ï¼ˆå¦‚æœæœ‰ï¼‰ã€‚
        æ ¼å¼ï¼šå…ˆæ˜¾ç¤ºå…³é”®è¯ï¼Œå†æ˜¾ç¤ºæ£€ç´¢åˆ°çš„è¡¨ä¿¡æ¯ã€‚
        """
        db_info: Dict[str, Any] = step_value.get("db_info") or {}
        
        # ä» step_value ä¸­è·å– BM25 åˆ†è¯ä¿¡æ¯
        bm25_tokens = step_value.get("bm25_tokens") or []
        user_query = step_value.get("user_query", "")
        
        # è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥ step_value ä¸­çš„å­—æ®µ
        logger.debug(f"schema_inspector step_value keys: {list(step_value.keys())}")
        logger.debug(f"bm25_tokens in step_value: {bm25_tokens}, type: {type(bm25_tokens)}")
        logger.debug(f"user_query in step_value: {user_query}")

        # æ„å»ºè¾“å‡ºå†…å®¹ï¼šå…ˆå…³é”®è¯ï¼Œåè¡¨ä¿¡æ¯
        parts = []
        
        # 1. å…³é”®è¯éƒ¨åˆ†
        if user_query:
            if isinstance(bm25_tokens, list) and bm25_tokens:
                # è¿‡æ»¤æ‰æ— æ„ä¹‰çš„å•å­—ç¬¦è¯ï¼ˆå¦‚"çš„"ã€"å„"ç­‰ï¼‰ï¼Œä¿ç•™æœ‰æ„ä¹‰çš„è¯
                meaningful_tokens = [token for token in bm25_tokens if len(token) > 1 or token.isalnum()]
                # å¦‚æœè¿‡æ»¤åè¿˜æœ‰è¯ï¼Œä½¿ç”¨è¿‡æ»¤åçš„ï¼›å¦åˆ™ä½¿ç”¨åŸå§‹çš„
                display_tokens = meaningful_tokens if meaningful_tokens else bm25_tokens
                
                # åªå±•ç¤ºå‰è‹¥å¹²ä¸ªåˆ†è¯ï¼Œé¿å…è¿‡é•¿
                max_tokens = 10
                shown_tokens = display_tokens[:max_tokens]
                tokens_str = "ã€".join(shown_tokens)
                if len(display_tokens) > max_tokens:
                    tokens_str += " ç­‰"
                
                # ç®€æ´æ ¼å¼ï¼šç›´æ¥æ˜¾ç¤ºå…³é”®è¯
                parts.append(f"å…³é”®è¯ï¼š{tokens_str}")
            else:
                # åˆ†è¯ç»“æœä¸ºç©ºæ—¶ï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢ä½œä¸ºå…³é”®è¯
                parts.append(f"å…³é”®è¯ï¼š{user_query}")
                logger.info(f"BM25 åˆ†è¯ç»“æœä¸ºç©ºï¼Œä½¿ç”¨åŸå§‹æŸ¥è¯¢ä½œä¸ºå…³é”®è¯: {user_query}")
        
        # 2. è¡¨ä¿¡æ¯éƒ¨åˆ†ï¼ˆæ”¾åœ¨å…³é”®è¯ä¸‹é¢ï¼‰
        table_text = self._format_db_info_compact(db_info)
        if table_text:
            parts.append(table_text)
        
        # ç»„åˆè¾“å‡º
        return "\n\n".join(parts) if parts else table_text

    @staticmethod
    def _format_chart_type_message(step_value: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–å›¾è¡¨ç±»å‹è¯´æ˜ï¼Œä¼˜å…ˆä» chart_config ä¸­è¯»å– typeï¼Œå…¶æ¬¡ä» chart_type å­—æ®µè¯»å–ã€‚
        """
        chart_config = step_value.get("chart_config") or {}
        chart_type = (
            (chart_config.get("type") if isinstance(chart_config, dict) else None)
            or step_value.get("chart_type")
            or "table"
        )
        # ç®€å•ç›´è§‚çš„æç¤ºè¯­
        return f"å›¾è¡¨ç±»å‹ï¼š{chart_type}"

    @staticmethod
    def _format_db_info(db_info: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–æ•°æ®åº“ä¿¡æ¯ï¼ŒåŒ…å«è¡¨åå’Œæ³¨é‡Šï¼ˆæ—§æ ¼å¼ï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
        :param db_info: æ•°æ®åº“ä¿¡æ¯
        :return: æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
        """
        if not db_info:
            return "å…±æ£€ç´¢0å¼ è¡¨."

        table_descriptions = []
        for table_name, table_info in db_info.items():
            # è·å–è¡¨æ³¨é‡Š
            table_comment = table_info.get("table_comment", "")
            if table_comment:
                table_descriptions.append(f"{table_name}({table_comment})")
            else:
                table_descriptions.append(table_name)

        tables_str = "ã€".join(table_descriptions)
        return f"å…±æ£€ç´¢{len(db_info)}å¼ è¡¨: {tables_str}."

    @staticmethod
    def _format_db_info_compact(db_info: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–æ•°æ®åº“ä¿¡æ¯ï¼Œç®€æ´æ ¼å¼ï¼šæ¯è¡Œä¸€ä¸ªè¡¨ï¼Œè¡¨åå’Œæ³¨é‡Šåˆ†å¼€æ˜¾ç¤º
        :param db_info: æ•°æ®åº“ä¿¡æ¯
        :return: æ ¼å¼åŒ–åçš„å­—ç¬¦ä¸²
        """
        if not db_info:
            return "æ£€ç´¢åˆ° 0 å¼ è¡¨"

        table_count = len(db_info)
        table_lines = []
        
        for table_name, table_info in db_info.items():
            # è·å–è¡¨æ³¨é‡Š
            table_comment = table_info.get("table_comment", "")
            if table_comment:
                table_lines.append(f"  â€¢ {table_name} - {table_comment}")
            else:
                table_lines.append(f"  â€¢ {table_name}")
        
        tables_text = "\n".join(table_lines)
        return f"æ£€ç´¢åˆ° {table_count} å¼ è¡¨ï¼š\n{tables_text}"

    @staticmethod
    async def _send_step_progress(
        response,
        step: str,
        step_name: str,
        status: str,
        progress_id: str,
    ) -> None:
        """
        å‘é€æ­¥éª¤è¿›åº¦ä¿¡æ¯
        :param response: å“åº”å¯¹è±¡
        :param step: æ­¥éª¤æ ‡è¯†ï¼ˆè‹±æ–‡ï¼‰
        :param step_name: æ­¥éª¤åç§°ï¼ˆä¸­æ–‡ï¼‰
        :param status: çŠ¶æ€ï¼ˆ"start" æˆ– "complete"ï¼‰
        :param progress_id: è¿›åº¦IDï¼ˆå”¯ä¸€æ ‡è¯†ï¼‰
        """
        if response:
            progress_data = {
                "type": "step_progress",
                "step": step,
                "stepName": step_name,
                "status": status,
                "progressId": progress_id,
            }
            formatted_message = {
                "data": progress_data,
                "dataType": DataTypeEnum.STEP_PROGRESS.value[0],
            }
            await response.write("data:" + json.dumps(formatted_message, ensure_ascii=False) + "\n\n")

    @staticmethod
    async def _send_response(
        response, content: Union[str, Dict[str, Any]], message_type: str = "continue", data_type: str = DataTypeEnum.ANSWER.value[0]
    ) -> None:
        """
        å‘é€å“åº”æ•°æ®
        :param response: å“åº”å¯¹è±¡
        :param content: å“åº”å†…å®¹ï¼Œå¯ä»¥æ˜¯å­—ç¬¦ä¸²æˆ–å­—å…¸
        :param message_type: æ¶ˆæ¯ç±»å‹
        :param data_type: æ•°æ®ç±»å‹
        """
        if response:
            if data_type == DataTypeEnum.ANSWER.value[0]:
                formatted_message = {
                    "data": {
                        "messageType": message_type,
                        "content": content,
                    },
                    "dataType": data_type,
                }
            else:
                # é€‚é…EChartè¡¨æ ¼
                formatted_message = {"data": content, "dataType": data_type}

            await response.write("data:" + json.dumps(formatted_message, ensure_ascii=False) + "\n\n")

    @staticmethod
    def _create_response(
        content: str, message_type: str = "continue", data_type: str = DataTypeEnum.ANSWER.value[0]
    ) -> str:
        """
        å°è£…å“åº”ç»“æ„ï¼ˆä¿æŒå‘åå…¼å®¹ï¼‰
        """
        res = {
            "data": {"messageType": message_type, "content": content},
            "dataType": data_type,
        }
        return "data:" + json.dumps(res, ensure_ascii=False) + "\n\n"

    async def cancel_task(self, task_id: str) -> bool:
        """
        å–æ¶ˆæŒ‡å®šçš„ä»»åŠ¡
        :param task_id: ä»»åŠ¡ID
        :return: æ˜¯å¦æˆåŠŸå–æ¶ˆ
        """
        if task_id in self.running_tasks:
            self.running_tasks[task_id]["cancelled"] = True
            return True
        return False
